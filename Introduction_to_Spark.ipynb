{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "alternate-convention",
   "metadata": {},
   "source": [
    "# Introduction to Apache Spark\n",
    "\n",
    "## What is Spark?\n",
    "\n",
    "- an Apache foundation **open source** project; not a product\n",
    "- enables highly **iterative** analysis on **massive** volumes of data at scale\n",
    "- an **in-memory computing** engine that works with **distributed** data, not a data store\n",
    "- **unified environment** for data scientists, developers and data engineers\n",
    "- radivally simplifies the process of developing **intelligent apps** fuelled by data\n",
    "\n",
    "## Spark Motivation\n",
    "\n",
    "Current popular programming models for cluster transform data flowing from stable storage to stable storage.\n",
    "\n",
    "Example: MapReduce\n",
    "\n",
    "<div style=\"display: inline-block; text-align: left; margin: 15px 0px 15px 0px;\"><img src='assets/mapReduceExample.jpg' alt='MapReduce example' width='580'/></div>\n",
    "\n",
    "**Benefits of data flow:** runtime can decide where to run tasks and can automatically recover from failures\n",
    "\n",
    "- Acyclic data flow is a powerful abstraction, but is not efficient for applications that repeatedly reuse a working set of data:\n",
    "    - **Iterative** algorithms (many in machine learning)\n",
    "    - **Interactive** data mining tools (R, Excel, Python)\n",
    "- Spark makes working sets a first-class concept to efficiently support these apps\n",
    "\n",
    "## Spark Goal\n",
    "\n",
    "- provide distributed memory abstractions for cluster to support apps with working sets\n",
    "- retain the attractive properties of MapReduce\n",
    "    1. fault tolerance (for crashes & stragglers)\n",
    "    2. data locality\n",
    "    3. scalability\n",
    "\n",
    "**Solution:** augment data flow model with \"resilient distributed datasets\" (RDDs)\n",
    "\n",
    "## Apache Spark is ...\n",
    "\n",
    "<div style=\"float:right; margin: 15px 0px 15px 0px;\"><img src='assets/logistic-regression.png' alt='Logistic regression in Hadoop and Spark' width='250'/></div>\n",
    "\n",
    "### 1. Fast\n",
    "- leverages aggressively cached in-memory distributed computing and JVM threads\n",
    "- faster than MapReduce (run workloads 100x faster)\n",
    "- apache spark achieves high performance for both batch and streaming data, using a state-of-the-art DAG scheduler, a query optimizer, and a physical execution engine\n",
    "\n",
    "\n",
    "### 2. Ease of use (for programmers)\n",
    "- written in Scala, an object-oriented, functional programming language\n",
    "- Scala, Python, and Java APIs\n",
    "- Scala and Python interactive shells\n",
    "- runs on Hadoop, Mesos, Kubernetes standalone or cloud\n",
    "\n",
    "<div style=\"float:right; margin: 15px 0px 15px 0px;\"><img src='assets/spark-stack.png' alt='Spart stack' width='250'/></div>\n",
    "\n",
    "### 3. General purpose\n",
    "- covers a wide range of workloads\n",
    "- provides SQL, streaming and complex analytics\n",
    "- powers a stac of libraries including SQL and Dataframes, MLlib for machine learning, GraphX, and Spark Streaming\n",
    "- you can combine theses libraries seamlessly in the same application\n",
    "\n",
    "## Spark Stack\n",
    "\n",
    "<div style=\"display: inline-block; text-aling: left; margin: 15px 0px 15px 0px;\"><img src='assets/spark-complete-stack.png' alt='Spark complete stack' width='580'/></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
